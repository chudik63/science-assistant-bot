{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7809bf2d-5461-4974-a34c-0f8ef3a322ac",
   "metadata": {},
   "source": [
    "## Импорт библиотек\n",
    "\n",
    "1) smolagents - библиотека для агентов. Импортируем следующие классы:\n",
    "   - `HfApiModel` - класс для инициализации мозга Qwen.2.5 агента;\n",
    "   - `ToolCallingAgent` - херня, которая связывает мозг и инструменты;\n",
    "   - `DuckDuckGoSearchTool` - библиотечный инструмент для того, чтобы модель сама могла искать необходимую инфу в инете;\n",
    "   - `tool` - будет использовать как декоратор для кастомных инструментов;\n",
    "   - `tools.Tool` - класс Tool для того, чтобы написать отдельный инструмент, чтобы модель норм формировала финальный ответ и не зацикливалась;\n",
    "\n",
    "2) langchain:\n",
    "    - `HugginFaceEmbeddings` - импортируем для того, чтобы получить готовые embeddings для слов;\n",
    "    - `InMemoryVectorStore` - херня, которая представляет из себя векторное хранилище (делаем для быстрого поиска по запрашиваемым embedding'ам);\n",
    "    - `RecursiveCharacterTextSplitter` - штука, которая разделит наш pdf файл на документы, дабы потом векторизовать этот файл;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b43908e-39da-4749-addb-199497821370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent, HfApiModel, DuckDuckGoSearchTool, tool\n",
    "from smolagents.tools import Tool\n",
    "\n",
    "from transformers import pipeline, MarianMTModel, MarianTokenizer\n",
    "from typing import Any, Optional, List, Dict\n",
    "\n",
    "# Для Юпитера\n",
    "import IPython\n",
    "IPython.display.clear_output(wait=True)\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "\n",
    "# два след. импорта для получения текущего времени\n",
    "import datetime \n",
    "import pytz\n",
    "\n",
    "# начальный промпт написан в *yaml файле\n",
    "import yaml\n",
    "\n",
    "import os\n",
    "\n",
    "# Хуйня для парсинга\n",
    "import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "import time\n",
    "import re\n",
    "# from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "# Беру свой токен из HugginFace, так как для импорта любой моделей он требуется\n",
    "TOKEN = \"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\"\n",
    "os.environ[\"HF_TOKEN\"] = TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32c16d4-62b3-46f0-b50a-ef26e95ba258",
   "metadata": {},
   "source": [
    "## Определение инструментов\n",
    "\n",
    "### Импорт необходимых моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fd8c42f-22ae-4d8a-9f1b-dfd901aa423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Модель из HugginFace. Импортируем Qwen2.5. Мозг Агента\n",
    "model = HfApiModel(\n",
    "    max_tokens=5000,\n",
    "    temperature=0.5,\n",
    "    model_id='Qwen/Qwen2.5-Coder-32B-Instruct',\n",
    "    custom_role_conversions=None\n",
    ")\n",
    "\n",
    "# Инициализируем Embeddings для упрощенного поиска\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Модель, делающая саммаризацию текста\n",
    "# Используем device='cpu', чтобы не было конфликтов при запуске на других ноутах\n",
    "# Выгоднее было бы использовать cuda (windows) или mps (macos), но не у всех доступна cuda :(\n",
    "summarizer = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\", device='cpu')\n",
    "\n",
    "# Разделитель нашего файла. Разделяет его на документы, дабы векторизовать файлик\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Инициализируем модель, которая переводит с русского языка на английский\n",
    "model_from_russian_to_english = \"Helsinki-NLP/opus-mt-ru-en\" \n",
    "tokenizer_russian = MarianTokenizer.from_pretrained(model_from_russian_to_english)\n",
    "model_russian = MarianMTModel.from_pretrained(model_from_russian_to_english)\n",
    "\n",
    "# Инициализируем моедель, которая с английского переводит на русский\n",
    "model_from_english_to_russian = \"Helsinki-NLP/opus-mt-en-ru\"\n",
    "tokenizer_english = MarianTokenizer.from_pretrained(model_from_english_to_russian)\n",
    "model_english = MarianMTModel.from_pretrained(model_from_english_to_russian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742538f2-bfc5-4447-bce4-55a3a5f12052",
   "metadata": {},
   "source": [
    "### Далее пишем сами инструменты и вспомогательные функции \n",
    "\n",
    "Сам инструмент определяется декоратором `@tool`\n",
    "\n",
    "#### Загрузка pdf файла для дальнейшей обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41fae3c-e825-4f66-892a-314d45d59b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(pdf_url: str, save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Download a PDF file from a given URL and save it to the specified path.\n",
    "    \n",
    "    Args:\n",
    "        pdf_url (str): The URL of the PDF file to download.\n",
    "        save_path (str): The file path where the PDF will be saved.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the response from the server is not successful (status code not 200).\n",
    "    \"\"\"\n",
    "    response = requests.get(pdf_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        raise ValueError(f\"Could not download PDF: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca222e49-a6bd-4d31-9ad2-8f9a375236d9",
   "metadata": {},
   "source": [
    "##### Пример использования функции:\n",
    "\n",
    "```python\n",
    "pdf_url = \"http://arxiv.org/pdf/1909.03550v1\"\n",
    "pdf_filename = pdf_url.split(\"/\")[-1] + \".pdf\" # 1909.03550v1.pdf\n",
    "pdf_path = os.path.join(\"downloads\", pdf_filename)\n",
    "download_pdf(pdf_url, pdf_path)\n",
    "```\n",
    "\n",
    "#### Вытаскиваем информацию из pdf файла и возвращаем векторизированный "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8836f0d1-c154-4d00-a0d1-bf1b5cbc02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_pdf_to_vector(pdf_path: str) -> InMemoryVectorStore:\n",
    "    \"\"\"\n",
    "    Extract text from a given PDF file and convert it into a vector store.\n",
    "\n",
    "    This function loads text from a PDF file specified by `pdf_path`, splits the text\n",
    "    into smaller documents, and creates an in-memory vector store using those documents.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the PDF file from which to extract text.\n",
    "\n",
    "    Returns:\n",
    "        InMemoryVectorStore: An in-memory vector store populated with \n",
    "        vectorized representations of the extracted documents.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified PDF file does not exist.\n",
    "        ValueError: If the PDF file cannot be processed.\n",
    "    \"\"\"\n",
    "    text_loader = PyPDFLoader(pdf_path)\n",
    "    text_contents = [doc.page_content for doc in text_loader.load()]\n",
    "\n",
    "    split_documents = splitter.create_documents(text_contents)\n",
    "    vector_store = InMemoryVectorStore.from_documents(split_documents, embedding_model)\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e14401-3e18-429c-a28d-c8539568d1df",
   "metadata": {},
   "source": [
    "#### Пример использования:\n",
    "\n",
    "```python\n",
    "pdf_path = os.path.join(\"downloads\", \"1910.14537v3.pdf\")\n",
    "vector = from_pdf_to_vector(pdf_path)\n",
    "vector.similarity_search(\"Gaussian-masked Directional Transformer.\")\n",
    "```\n",
    "\n",
    "### Делаем Саммаризацию выжимок из documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8255d6a-6639-46ef-abfc-410b3537ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text_article(documents: List[Document],\n",
    "                  percent_to_keep: float = 0.2) -> str:\n",
    "    \"\"\"\n",
    "    Generate a summary of the given documents.\n",
    "\n",
    "    This function extracts text from a list of Document objects, \n",
    "    and uses a summarization model to generate a concise summary \n",
    "    while keeping a specified percentage of the original text. \n",
    "    The percentage to keep can be defined through the \n",
    "    `percent_to_keep` parameter, allowing for control over \n",
    "    the length of the summary.\n",
    "\n",
    "    Args:\n",
    "        documents (List[Document]): A list of Document objects \n",
    "            containing the text to be summarized.\n",
    "        summarizer (pipeline): The summarization model from HuggingFace \n",
    "            transformers used to generate the summary.\n",
    "        percent_to_keep (float, optional): The percentage of the original \n",
    "            text length to retain in the summary (default is 0.2, which \n",
    "            means 20%).\n",
    "\n",
    "    Returns:\n",
    "        str: The generated summary of the documents, which reflects \n",
    "        the most important points based on the provided content.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the list of documents is empty or if \n",
    "        the calculated target length is invalid.\n",
    "    \"\"\"\n",
    "    \n",
    "    context = \"\\n\".join([re.sub(r'\\s+', ' ', doc.page_content).strip() for doc in documents])\n",
    "    original_length = len(context.split())\n",
    "    target_length = int(original_length * percent_to_keep)\n",
    "    target_length = max(30, min(target_length, 1024))\n",
    "\n",
    "    summary = summarizer(context, max_length=target_length,\n",
    "                         min_length=max(30, int(target_length * 0.8)),\n",
    "                         do_sample=False)\n",
    "    return summary[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90a339-eb12-4b52-a825-4959502d9676",
   "metadata": {},
   "source": [
    "#### Пример исползования\n",
    "\n",
    "```python\n",
    "pdf_path = os.path.join(\"downloads\", \"1910.14537v3.pdf\")\n",
    "vector = from_pdf_to_vector(pdf_path)\n",
    "documents = vector.similarity_search(\"Gaussian-masked Directional Transformer.\")\n",
    "summarize_text_article(documents, 0.2)\n",
    "```\n",
    "\n",
    "### Пишем инструмент для поиска статей по запросу и выжимок, которые будет делать ГПТ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5679befe-169c-430a-9933-5755fb18728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_arxiv(query: str, max_results: int, summarize: bool) -> List:\n",
    "    \"\"\"\n",
    "    A tool that searches for articles on arXiv based on a query and optionally generates summaries.\n",
    "\n",
    "    This function queries the arXiv API to retrieve scholarly articles matching the provided search query. \n",
    "    It supports downloading PDFs of the articles, converting them into vector representations, and generating \n",
    "    summaries if requested. The function is designed to handle errors gracefully, including retries for network \n",
    "    issues and validation of input parameters.\n",
    "\n",
    "    Args:\n",
    "        query: The search query for finding articles on arXiv. This can be a topic, keyword, or phrase \n",
    "                     (e.g., \"quantum computing\", \"machine learning applications\").\n",
    "        max_results: The maximum number of articles to return. Must be between 1 and 5 (inclusive). \n",
    "                           This limit ensures manageable processing times and avoids overloading the system.\n",
    "        summarize: A flag indicating whether to generate summaries for the retrieved articles. If True, \n",
    "                          the function will process the downloaded PDFs to extract and summarize key information.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of dictionaries, where each dictionary contains the following keys:\n",
    "            - 'title' (str): The title of the article.\n",
    "            - 'pdf_url' (str): The URL of the article's PDF on arXiv.\n",
    "            - 'local_pdf_path' (str): The local file path where the PDF has been downloaded.\n",
    "            - 'summary' (str): A summary of the article's content (if `summarize` is True); otherwise, an empty string.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `max_results` is less than 1 or greater than 5.\n",
    "        RuntimeError: If there are repeated failures in fetching data from arXiv after multiple retry attempts.\n",
    "\n",
    "    Notes:\n",
    "        - The function uses exponential backoff for retrying failed requests to the arXiv API.\n",
    "        - PDFs are downloaded into a local \"downloads\" directory, which is created if it does not already exist.\n",
    "        - Summaries are generated using similarity search over vectorized PDF content, followed by text summarization techniques.\n",
    "        - If a PDF download fails, the corresponding article is skipped, and the function proceeds with the next result.\n",
    "\n",
    "    Example Usage:\n",
    "        # Search for 3 articles on \"neural networks\" and generate summaries\n",
    "        results = search_arxiv(query=\"neural networks\", max_results=3, summarize=True)\n",
    "        for result in results:\n",
    "            print(f\"Title: {result['title']}\")\n",
    "            print(f\"PDF URL: {result['pdf_url']}\")\n",
    "            print(f\"Summary: {result['summary']}\\n\")\n",
    "\n",
    "        # Handle invalid input\n",
    "        try:\n",
    "            results = search_arxiv(query=\"attention in machine learning\", max_results=10, summarize=True)\n",
    "        except ValueError as e:\n",
    "            print(e)  # Output: max_results must be between 1 and 5.\n",
    "    \"\"\"\n",
    "    print(\"In process of finding articles...\")\n",
    "    if max_results > 5 or max_results < 1:\n",
    "        return \"max_results must be between 1 and 5.\"\n",
    "\n",
    "    base_url = \"http://export.arxiv.org/api/query\"\n",
    "    params = {\n",
    "        \"search_query\": query,\n",
    "        \"start\": 0,\n",
    "        \"max_results\": max_results\n",
    "    }\n",
    "\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            break\n",
    "        except (requests.exceptions.RequestException, ConnectionResetError) as e:\n",
    "            if attempt < 4:\n",
    "                time.sleep(2 ** attempt)\n",
    "                continue\n",
    "            return f\"Error fetching data from arXiv after {attempt + 1} attempts: {e}\"\n",
    "\n",
    "    root = ET.fromstring(response.content)\n",
    "    entries = []\n",
    "    os.makedirs(\"downloads\", exist_ok=True)\n",
    "\n",
    "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        pdf_url = entry.find('{http://www.w3.org/2005/Atom}link[@title=\"pdf\"]').attrib['href']\n",
    "\n",
    "        pdf_filename = pdf_url.split(\"/\")[-1] + \".pdf\"\n",
    "        pdf_path = os.path.join(\"downloads\", pdf_filename)\n",
    "        try:\n",
    "            download_pdf(pdf_url, pdf_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download PDF: {e}\")\n",
    "            continue\n",
    "        \n",
    "        vector = from_pdf_to_vector(pdf_path)\n",
    "        documents = vector.similarity_search(query)\n",
    "\n",
    "        summary_text = summarize_text_article(documents) if summarize else \"\"\n",
    "\n",
    "        entries.append({\n",
    "            'title': title,\n",
    "            'pdf_url': pdf_url,\n",
    "            'local_pdf_path': pdf_path,\n",
    "            'summary': summary_text\n",
    "        })\n",
    "\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847dc296-8c8f-49b2-8e3c-3fd3076dc986",
   "metadata": {},
   "source": [
    "#### Пример использования\n",
    "\n",
    "```python\n",
    "search_arxiv(\"Attention in Machine Learning\", 2, True)\n",
    "```\n",
    "\n",
    "### Следующая функция тестовая для проверки того, что агент не ебанутый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa118211-bd29-441f-87c5-71e6cb2bbbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_time_in_timezone(timezone: str) -> str:\n",
    "    \"\"\"\n",
    "    A tool that fetches the current local time in a specified timezone.\n",
    "    \n",
    "    Args:\n",
    "        timezone: A string representing a valid timezone (e.g., 'America/New_York').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tz = pytz.timezone(timezone)\n",
    "        local_time = datetime.datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        return f\"The current local time in {timezone} is: {local_time}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching time for timezone '{timezone}': {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e334998e-4c70-406b-a0a3-dabd54019c85",
   "metadata": {},
   "source": [
    "#### Пример использования\n",
    "\n",
    "```python\n",
    "get_current_time_in_timezone(\"Europe/London\")\n",
    "```\n",
    "\n",
    "### Определяем класс, который будет управлять финальным ответом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d15fd049-1595-4c56-9421-7a7f8e72cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalAnswerTool(Tool):\n",
    "    name = \"final_answer\"\n",
    "    description = \"Provides a final answer to the given problem.\"\n",
    "    inputs = {'answer': {'type': 'any', 'description': 'The final answer to the problem'}}\n",
    "    output_type = \"any\"\n",
    "\n",
    "    def forward(self, answer: Any) -> Any:\n",
    "        return answer\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_initialized = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750c6dd-1471-4302-8cbb-6ccbc075893b",
   "metadata": {},
   "source": [
    "### Читаем подготовленный файл для того, чтобы мозгу Агента (Qwen2.5) дать необходимые указания по поводу нашего функционала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "05a95483-520e-4b6f-ab46-12555428ed01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert assistant who can solve any task by using the available tools.\\nTo solve the task, '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"prompts.yaml\", 'r') as stream:\n",
    "        prompt_templates = yaml.safe_load(stream)\n",
    "except FileNotFoundError:\n",
    "    prompt_templates = {}  # Если файл не найден, используем пустой словарь\n",
    "\n",
    "final_answer = FinalAnswerTool()\n",
    "web_search = DuckDuckGoSearchTool()\n",
    "prompt_templates['system_prompt'][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081f8f3-7904-4480-9879-f856b06e55f4",
   "metadata": {},
   "source": [
    "### Инициализируем наешго агента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1c06fa94-ccb5-4727-b783-fc4e87427609",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent =  ToolCallingAgent(\n",
    "    model=model,\n",
    "    tools=[final_answer, web_search, get_current_time_in_timezone, search_arxiv],\n",
    "    max_steps=5,\n",
    "    verbosity_level=1,\n",
    "    grammar=None,\n",
    "    planning_interval=None,\n",
    "    name=\"AndrewSolver\",\n",
    "    description=None,\n",
    "    prompt_templates=prompt_templates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a8b63-6b25-416a-a505-d01a25e1503c",
   "metadata": {},
   "source": [
    "### Тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4e763459-fe56-4f3d-81f0-f31cbadf38cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Send me 3 articles about attention. Also make your own summary and send me some link\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run - AndrewSolver</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Send me 3 articles about attention. Also make your own summary and send me some link</span>                            <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ──────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run - AndrewSolver\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mSend me 3 articles about attention. Also make your own summary and send me some link\u001b[0m                            \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'search_arxiv' with arguments: {'summarize': True, 'query': 'attention', 'max_results': 3}        │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'search_arxiv' with arguments: {'summarize': True, 'query': 'attention', 'max_results': 3}        │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In process of finding articles...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: Error fetching data from arXiv after <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> attempts: <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Connection aborted.'</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConnectionResetError</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'Connection reset by peer'</span><span style=\"font-weight: bold\">))</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: Error fetching data from arXiv after \u001b[1;36m5\u001b[0m attempts: \u001b[1m(\u001b[0m\u001b[32m'Connection aborted.'\u001b[0m, \u001b[1;35mConnectionResetError\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m54\u001b[0m, \n",
       "\u001b[32m'Connection reset by peer'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 39.60 seconds| Input tokens: 2,768 | Output tokens: 32]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 39.60 seconds| Input tokens: 2,768 | Output tokens: 32]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'query': 'attention articles'}                                      │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'query': 'attention articles'}                                      │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: ## Search Results\n",
       "\n",
       "|Working Memory and Attention - A Conceptual Analysis and \n",
       "Review<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://pmc.ncbi.nlm.nih.gov/articles/PMC6688548/)</span>\n",
       "There is broad agreement that working memory is closely related to attention. This article delineates several \n",
       "theoretical options for conceptualizing this link, and evaluates their viability in light of their theoretical \n",
       "implications and the <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "\n",
       "|Attention in Psychology, Neuroscience, and Machine Learning<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://pmc.ncbi.nlm.nih.gov/articles/PMC7177153/)</span>\n",
       "Attention is the important ability to flexibly control limited computational resources. It has been studied in \n",
       "conjunction with many other topics in neuroscience and psychology including awareness, vigilance, saliency, \n",
       "executive control, and <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "\n",
       "|The Role of Attention in Learning in the Digital Age - PMC<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://pmc.ncbi.nlm.nih.gov/articles/PMC6430174/)</span>\n",
       "This kind of collaboration requires testing assumptions about what attention and learning are, what level of \n",
       "analysis is appropriate for answering what kinds of questions and how to effectively translate and make meaning of \n",
       "research that occurs in highly controlled environments for the complex real world |cf. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61</span><span style=\"font-weight: bold\">]</span>.\n",
       "\n",
       "|Full article: Attention: Theory, Principles, Models and \n",
       "Applications<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.tandfonline.com/doi/full/10.1080/10447318.2021.1874741)</span>\n",
       "In this article, we introduce the theories of attention from which models and principles are derived, within the \n",
       "context of a descriptive model of human attention and performance shown in Figure <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> . Such principles, if applied \n",
       "in design, can potentially remediate problems of attention such as those described above.\n",
       "\n",
       "|Attention - Psychology Today<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.psychologytoday.com/us/basics/attention)</span>\n",
       "The ability to pay attention to important things—and ignore the rest—has been a crucial survival skill throughout \n",
       "human history. Attention can help us focus our awareness on a particular <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "\n",
       "|<span style=\"font-weight: bold\">(</span>PDF<span style=\"font-weight: bold\">)</span> Attention and Perception - \n",
       "ResearchGate<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.researchgate.net/publication/274699544_Attention_and_Perception)</span>\n",
       "This article discusses several key issues concerning the study of attention and its relation to visual perception, \n",
       "with an emphasis on behavioral and experiential aspects.\n",
       "\n",
       "|Attention - Latest research and news | Nature<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.nature.com/subjects/attention)</span>\n",
       "Attention articles from across Nature Portfolio Attention is a cognitive process in which a person or animal \n",
       "concentrates on one thing in particular. To attend to something is to focus, heed or <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "\n",
       "|We know what attention is! - ScienceDirect<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.sciencedirect.com/science/article/pii/S1364661323002863)</span>\n",
       "Attention is one of the most thoroughly investigated psychological phenomena, yet skepticism about attention is \n",
       "widespread: we do not know what it is,…\n",
       "\n",
       "|Attention | Nature Neuroscience<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.nature.com/subjects/attention/neuro)</span>\n",
       "Attention alters neural responses that encode different aspects of visual stimuli, but exactly how these changes \n",
       "together modulate the encoded spatial representation of a scene remains unclear.\n",
       "\n",
       "|Attention and its importance for education - \n",
       "IBE<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://solportal.ibe-unesco.org/articles/attention-and-its-importance-for-education/)</span>\n",
       "Attention is brain processes that let us focus on a specific stimulus or task, while filtering out distractions <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. \n",
       "It is a complex set of processes that involves specialized networks to carry out functions such as achieving and \n",
       "maintaining vigilance, focusing on something, and controlling thoughts and feelings <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Attention is essential for \n",
       "many cognitive processes, such as learning, problem <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: ## Search Results\n",
       "\n",
       "|Working Memory and Attention - A Conceptual Analysis and \n",
       "Review\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://pmc.ncbi.nlm.nih.gov/articles/PMC6688548/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "There is broad agreement that working memory is closely related to attention. This article delineates several \n",
       "theoretical options for conceptualizing this link, and evaluates their viability in light of their theoretical \n",
       "implications and the \u001b[33m...\u001b[0m\n",
       "\n",
       "|Attention in Psychology, Neuroscience, and Machine Learning\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://pmc.ncbi.nlm.nih.gov/articles/PMC7177153/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Attention is the important ability to flexibly control limited computational resources. It has been studied in \n",
       "conjunction with many other topics in neuroscience and psychology including awareness, vigilance, saliency, \n",
       "executive control, and \u001b[33m...\u001b[0m\n",
       "\n",
       "|The Role of Attention in Learning in the Digital Age - PMC\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://pmc.ncbi.nlm.nih.gov/articles/PMC6430174/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "This kind of collaboration requires testing assumptions about what attention and learning are, what level of \n",
       "analysis is appropriate for answering what kinds of questions and how to effectively translate and make meaning of \n",
       "research that occurs in highly controlled environments for the complex real world |cf. \u001b[1;36m61\u001b[0m\u001b[1m]\u001b[0m.\n",
       "\n",
       "|Full article: Attention: Theory, Principles, Models and \n",
       "Applications\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.tandfonline.com/doi/full/10.1080/10447318.2021.1874741\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "In this article, we introduce the theories of attention from which models and principles are derived, within the \n",
       "context of a descriptive model of human attention and performance shown in Figure \u001b[1;36m1\u001b[0m . Such principles, if applied \n",
       "in design, can potentially remediate problems of attention such as those described above.\n",
       "\n",
       "|Attention - Psychology Today\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.psychologytoday.com/us/basics/attention\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "The ability to pay attention to important things—and ignore the rest—has been a crucial survival skill throughout \n",
       "human history. Attention can help us focus our awareness on a particular \u001b[33m...\u001b[0m\n",
       "\n",
       "|\u001b[1m(\u001b[0mPDF\u001b[1m)\u001b[0m Attention and Perception - \n",
       "ResearchGate\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.researchgate.net/publication/274699544_Attention_and_Perception\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "This article discusses several key issues concerning the study of attention and its relation to visual perception, \n",
       "with an emphasis on behavioral and experiential aspects.\n",
       "\n",
       "|Attention - Latest research and news | Nature\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.nature.com/subjects/attention\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Attention articles from across Nature Portfolio Attention is a cognitive process in which a person or animal \n",
       "concentrates on one thing in particular. To attend to something is to focus, heed or \u001b[33m...\u001b[0m\n",
       "\n",
       "|We know what attention is! - ScienceDirect\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.sciencedirect.com/science/article/pii/S1364661323002863\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Attention is one of the most thoroughly investigated psychological phenomena, yet skepticism about attention is \n",
       "widespread: we do not know what it is,…\n",
       "\n",
       "|Attention | Nature Neuroscience\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.nature.com/subjects/attention/neuro\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Attention alters neural responses that encode different aspects of visual stimuli, but exactly how these changes \n",
       "together modulate the encoded spatial representation of a scene remains unclear.\n",
       "\n",
       "|Attention and its importance for education - \n",
       "IBE\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://solportal.ibe-unesco.org/articles/attention-and-its-importance-for-education/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Attention is brain processes that let us focus on a specific stimulus or task, while filtering out distractions \u001b[1;36m1\u001b[0m. \n",
       "It is a complex set of processes that involves specialized networks to carry out functions such as achieving and \n",
       "maintaining vigilance, focusing on something, and controlling thoughts and feelings \u001b[1;36m2\u001b[0m. Attention is essential for \n",
       "many cognitive processes, such as learning, problem \u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 5.34 seconds| Input tokens: 5,634 | Output tokens: 51]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 5.34 seconds| Input tokens: 5,634 | Output tokens: 51]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m3\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'query': 'attention articles pdf links'}                            │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'web_search' with arguments: {'query': 'attention articles pdf links'}                            │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: ## Search Results\n",
       "\n",
       "|<span style=\"font-weight: bold\">(</span>PDF<span style=\"font-weight: bold\">)</span> Attention: Theory, Principles, Models and Applications - \n",
       "ResearchGate<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.researchgate.net/publication/349082014_Attention_Theory_Principles_Models_and_Application</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">s)</span>\n",
       "Q3 We discuss two general concepts of attention: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span> As a filter of selective attention that selects and admits \n",
       "channels of information from the environment to be processed; <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span> as a resource to <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "\n",
       "|<span style=\"font-weight: bold\">(</span>PDF<span style=\"font-weight: bold\">)</span> Attention: Multiple types, brain resonances, psychological \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.researchgate.net/publication/350586329_Attention_Multiple_types_brain_resonances_psychological_fun</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">ctions_and_conscious_states)</span>\n",
       "This article describes neural models of attention. Since attention is not a disembodied process, the article \n",
       "explains how brain processes of consciousness, learning, expectation, attention <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "\n",
       "| Oxford Handbooks Online - Brain and \n",
       "Cognition<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.brainandcognition.org/wp-content/uploads/2015/07/Attention.pdf)</span>\n",
       "Attention: Time Capsule <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2013</span> Anna C. <span style=\"font-weight: bold\">(</span>Kia<span style=\"font-weight: bold\">)</span> Nobre and Sabine Kastner The Oxford Handbook of Attention Edited by Anna\n",
       "C. <span style=\"font-weight: bold\">(</span>Kia<span style=\"font-weight: bold\">)</span> Nobre and Sabine Kastner Oxford Handbooks Online Abstract and Keywords <span style=\"color: #008000; text-decoration-color: #008000\">'Attention'</span> is a core and \n",
       "fundamental aspect of cognition. Accordingly it engages a sizeable and thriving research community.\n",
       "\n",
       "|Working Memory and Attention - A Conceptual Analysis and \n",
       "Review<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://pmc.ncbi.nlm.nih.gov/articles/PMC6688548/)</span>\n",
       "There is a broad consensus that working memory and attention are intimately linked <span style=\"font-weight: bold\">(</span>Awh, Jonides, &amp; Reuter-Lorenz, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1998</span>; Baddeley, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1993</span>; Chun, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2011</span>; Cowan, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1995</span>; Gazzaley &amp; Nobre, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2012</span>; Kane, Bleckley, Conway, &amp; Engle, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2001</span>; \n",
       "Kiyonaga &amp; Egner, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2014</span>; Oberauer, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2009</span>; Olivers, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2008</span><span style=\"font-weight: bold\">)</span>.But what is it that we agree upon? Both working memory and \n",
       "attention can be conceptualized in different ways <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "\n",
       "| Attention as a Cognitive Function - biomedres.us<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://biomedres.us/pdfs/BJSTR.MS.ID.007836.pdf)</span>\n",
       "Review Article ISSN: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2574</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1241</span> DOI: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.26717</span>/BJSTR.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023.49</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">007836</span> Attention as a Cognitive Function Theofilidis \n",
       "Antonis1*, Savvidis George2 and Sofologi Maria3 1Academic scholarship of the Department of Obstetrics, University \n",
       "of Western Macedonia, Greece 2PhD candidate, Department of Obstetrics, University of Western Macedonia, Greece \n",
       "3Cognitive psychologist, Greece\n",
       "\n",
       "|<span style=\"font-weight: bold\">(</span>PDF<span style=\"font-weight: bold\">)</span> Cognitive neuroscience of attention - \n",
       "ResearchGate<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.researchgate.net/publication/318949795_Cognitive_neuroscience_of_attention)</span>\n",
       "It has been associated with two separate brain networks, one involved in focusing attention voluntarily using \n",
       "top-down mechanisms <span style=\"font-weight: bold\">(</span>i.e., the dorsal attention system<span style=\"font-weight: bold\">)</span> and a second that reorients <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "\n",
       "| Copyright American Psychological Association.<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.apa.org/pubs/books/attention-sample-pages.pdf)</span>\n",
       "of attention is the nerve of the whole psychological system\" <span style=\"font-weight: bold\">(</span>p. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">173</span><span style=\"font-weight: bold\">)</span>. Pillsbury <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1908</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1973</span><span style=\"font-weight: bold\">)</span> provided a similarly \n",
       "strong assessment of the impor - tance of attention, asserting that effects of attention <span style=\"color: #008000; text-decoration-color: #008000\">\"extend to every part of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the physical organism, and are among the most profound facts of mind\"</span> <span style=\"font-weight: bold\">(</span>p. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>.\n",
       "\n",
       "| TWELVE THESES ON ATTENTION - Friends of \n",
       "Attention<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://friendsofattention.net/sites/default/files/2020-05/TWELVE-THESES-ON-ATTENTION-2019.pdf)</span>\n",
       "found, but it takes an effort of attention to find them, and this seeking is also attention's effort to heal \n",
       "itself. This attention-which-seeks often takes the form of an intense and near-devotional expectation and \n",
       "anticipation that refuses to know what it expects and anticipates. X. What is needed is an ethics of attention. \n",
       "This is akin to a <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "\n",
       "| week <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> attention - Scholars at \n",
       "Harvard<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://scholar.harvard.edu/sites/scholar.harvard.edu/files/volkman/files/week_11_attention.pdf)</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"Attention is a core property of all perceptual and cognitive operations. Given limited capacity to process </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">competing options, attentional mechanisms o select, o modulate, and o sustain focus |vigilance] on information most</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relevant for behavior.\"</span> Attention and memory are the foundations of learning Chun, Golomb, &amp; Turk-Browne, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2011</span>, p. \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "\n",
       "| ATTENTION TO ATTENTION - BeMindful.org<span style=\"font-weight: bold\">](</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.bemindful.org/articles/openfocus.pdf)</span>\n",
       "Attention styles are defined. Attention biases are described and their impact on physiology and experience is \n",
       "suggested. Optimum attention style combinations are suggested. Research data are presented. Talk therapy and \n",
       "attention training are contrasted. How we use styles of attention to manage our experience is discussed. An\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: ## Search Results\n",
       "\n",
       "|\u001b[1m(\u001b[0mPDF\u001b[1m)\u001b[0m Attention: Theory, Principles, Models and Applications - \n",
       "ResearchGate\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.researchgate.net/publication/349082014_Attention_Theory_Principles_Models_and_Application\u001b[0m\n",
       "\u001b[4;94ms\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Q3 We discuss two general concepts of attention: \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m As a filter of selective attention that selects and admits \n",
       "channels of information from the environment to be processed; \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m as a resource to \u001b[33m...\u001b[0m\n",
       "\n",
       "|\u001b[1m(\u001b[0mPDF\u001b[1m)\u001b[0m Attention: Multiple types, brain resonances, psychological \n",
       "\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.researchgate.net/publication/350586329_Attention_Multiple_types_brain_resonances_psychological_fun\u001b[0m\n",
       "\u001b[4;94mctions_and_conscious_states\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "This article describes neural models of attention. Since attention is not a disembodied process, the article \n",
       "explains how brain processes of consciousness, learning, expectation, attention \u001b[33m...\u001b[0m\n",
       "\n",
       "| Oxford Handbooks Online - Brain and \n",
       "Cognition\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.brainandcognition.org/wp-content/uploads/2015/07/Attention.pdf\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Attention: Time Capsule \u001b[1;36m2013\u001b[0m Anna C. \u001b[1m(\u001b[0mKia\u001b[1m)\u001b[0m Nobre and Sabine Kastner The Oxford Handbook of Attention Edited by Anna\n",
       "C. \u001b[1m(\u001b[0mKia\u001b[1m)\u001b[0m Nobre and Sabine Kastner Oxford Handbooks Online Abstract and Keywords \u001b[32m'Attention'\u001b[0m is a core and \n",
       "fundamental aspect of cognition. Accordingly it engages a sizeable and thriving research community.\n",
       "\n",
       "|Working Memory and Attention - A Conceptual Analysis and \n",
       "Review\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://pmc.ncbi.nlm.nih.gov/articles/PMC6688548/\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "There is a broad consensus that working memory and attention are intimately linked \u001b[1m(\u001b[0mAwh, Jonides, & Reuter-Lorenz, \n",
       "\u001b[1;36m1998\u001b[0m; Baddeley, \u001b[1;36m1993\u001b[0m; Chun, \u001b[1;36m2011\u001b[0m; Cowan, \u001b[1;36m1995\u001b[0m; Gazzaley & Nobre, \u001b[1;36m2012\u001b[0m; Kane, Bleckley, Conway, & Engle, \u001b[1;36m2001\u001b[0m; \n",
       "Kiyonaga & Egner, \u001b[1;36m2014\u001b[0m; Oberauer, \u001b[1;36m2009\u001b[0m; Olivers, \u001b[1;36m2008\u001b[0m\u001b[1m)\u001b[0m.But what is it that we agree upon? Both working memory and \n",
       "attention can be conceptualized in different ways \u001b[33m...\u001b[0m\n",
       "\n",
       "| Attention as a Cognitive Function - biomedres.us\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://biomedres.us/pdfs/BJSTR.MS.ID.007836.pdf\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Review Article ISSN: \u001b[1;36m2574\u001b[0m \u001b[1;36m-1241\u001b[0m DOI: \u001b[1;36m10.26717\u001b[0m/BJSTR.\u001b[1;36m2023.49\u001b[0m.\u001b[1;36m007836\u001b[0m Attention as a Cognitive Function Theofilidis \n",
       "Antonis1*, Savvidis George2 and Sofologi Maria3 1Academic scholarship of the Department of Obstetrics, University \n",
       "of Western Macedonia, Greece 2PhD candidate, Department of Obstetrics, University of Western Macedonia, Greece \n",
       "3Cognitive psychologist, Greece\n",
       "\n",
       "|\u001b[1m(\u001b[0mPDF\u001b[1m)\u001b[0m Cognitive neuroscience of attention - \n",
       "ResearchGate\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.researchgate.net/publication/318949795_Cognitive_neuroscience_of_attention\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "It has been associated with two separate brain networks, one involved in focusing attention voluntarily using \n",
       "top-down mechanisms \u001b[1m(\u001b[0mi.e., the dorsal attention system\u001b[1m)\u001b[0m and a second that reorients \u001b[33m...\u001b[0m\n",
       "\n",
       "| Copyright American Psychological Association.\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.apa.org/pubs/books/attention-sample-pages.pdf\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "of attention is the nerve of the whole psychological system\" \u001b[1m(\u001b[0mp. \u001b[1;36m173\u001b[0m\u001b[1m)\u001b[0m. Pillsbury \u001b[1m(\u001b[0m\u001b[1;36m1908\u001b[0m/\u001b[1;36m1973\u001b[0m\u001b[1m)\u001b[0m provided a similarly \n",
       "strong assessment of the impor - tance of attention, asserting that effects of attention \u001b[32m\"extend to every part of \u001b[0m\n",
       "\u001b[32mthe physical organism, and are among the most profound facts of mind\"\u001b[0m \u001b[1m(\u001b[0mp. \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m.\n",
       "\n",
       "| TWELVE THESES ON ATTENTION - Friends of \n",
       "Attention\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://friendsofattention.net/sites/default/files/2020-05/TWELVE-THESES-ON-ATTENTION-2019.pdf\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "found, but it takes an effort of attention to find them, and this seeking is also attention's effort to heal \n",
       "itself. This attention-which-seeks often takes the form of an intense and near-devotional expectation and \n",
       "anticipation that refuses to know what it expects and anticipates. X. What is needed is an ethics of attention. \n",
       "This is akin to a \u001b[33m...\u001b[0m\n",
       "\n",
       "| week \u001b[1;36m11\u001b[0m attention - Scholars at \n",
       "Harvard\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://scholar.harvard.edu/sites/scholar.harvard.edu/files/volkman/files/week_11_attention.pdf\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "\u001b[32m\"Attention is a core property of all perceptual and cognitive operations. Given limited capacity to process \u001b[0m\n",
       "\u001b[32mcompeting options, attentional mechanisms o select, o modulate, and o sustain focus |vigilance\u001b[0m\u001b[32m]\u001b[0m\u001b[32m on information most\u001b[0m\n",
       "\u001b[32mrelevant for behavior.\"\u001b[0m Attention and memory are the foundations of learning Chun, Golomb, & Turk-Browne, \u001b[1;36m2011\u001b[0m, p. \n",
       "\u001b[1;36m73\u001b[0m \u001b[1;36m5\u001b[0m\n",
       "\n",
       "| ATTENTION TO ATTENTION - BeMindful.org\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\u001b[4;94mhttps://www.bemindful.org/articles/openfocus.pdf\u001b[0m\u001b[4;94m)\u001b[0m\n",
       "Attention styles are defined. Attention biases are described and their impact on physiology and experience is \n",
       "suggested. Optimum attention style combinations are suggested. Research data are presented. Talk therapy and \n",
       "attention training are contrasted. How we use styles of attention to manage our experience is discussed. An\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 3: Duration 6.45 seconds| Input tokens: 9,298 | Output tokens: 72]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 3: Duration 6.45 seconds| Input tokens: 9,298 | Output tokens: 72]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m4\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': \"Here are 3 articles about attention along with         │\n",
       "│ summaries and links:\\\\n1. **Attention: Theory, Principles, Models and Applications**\\\\n   *Summary*: This       │\n",
       "│ article discusses theories of attention from which models and principles are derived, focusing on a descriptive │\n",
       "│ model of human attention and performance. It explores how principles of attention can be applied in design to   │\n",
       "│ remediate attention-related problems.\\\\n   *Link*:                                                              │\n",
       "│ https://www.researchgate.net/publication/349082014_Attention_Theory_Principles_Models_and_Applications          │\n",
       "│ \\\\\\\\[PDF]\\\\n2. **Attention: Multiple types, brain resonances, psychological functions and conscious states**\\\\n │\n",
       "│ *Summary*: This article delves into neural models of attention, explaining how brain processes of               │\n",
       "│ consciousness, learning, expectation, and attention interact. It highlights the role of brain resonances in     │\n",
       "│ different types of attention and their impact on conscious states.\\\\n   *Link*:                                 │\n",
       "│ https://www.researchgate.net/publication/350586329_Attention_Multiple_types_brain_resonances_psychological_func │\n",
       "│ tions_and_conscious_states \\\\\\\\[PDF]\\\\n3. **Attention - The Oxford Handbook of Attention**\\\\n   *Summary*: This │\n",
       "│ chapter from the Oxford Handbook of Attention provides an overview of attention as a fundamental aspect of      │\n",
       "│ cognition. It discusses the research community's engagement with attention and its various facets, including    │\n",
       "│ selective attention, sustained attention, and divided attention.\\\\n   *Link*:                                   │\n",
       "│ https://www.brainandcognition.org/wp-content/uploads/2015/07/Attention.pdf \\\\\\\\[PDF]\"}                          │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': \"Here are 3 articles about attention along with         │\n",
       "│ summaries and links:\\\\n1. **Attention: Theory, Principles, Models and Applications**\\\\n   *Summary*: This       │\n",
       "│ article discusses theories of attention from which models and principles are derived, focusing on a descriptive │\n",
       "│ model of human attention and performance. It explores how principles of attention can be applied in design to   │\n",
       "│ remediate attention-related problems.\\\\n   *Link*:                                                              │\n",
       "│ https://www.researchgate.net/publication/349082014_Attention_Theory_Principles_Models_and_Applications          │\n",
       "│ \\\\\\\\[PDF]\\\\n2. **Attention: Multiple types, brain resonances, psychological functions and conscious states**\\\\n │\n",
       "│ *Summary*: This article delves into neural models of attention, explaining how brain processes of               │\n",
       "│ consciousness, learning, expectation, and attention interact. It highlights the role of brain resonances in     │\n",
       "│ different types of attention and their impact on conscious states.\\\\n   *Link*:                                 │\n",
       "│ https://www.researchgate.net/publication/350586329_Attention_Multiple_types_brain_resonances_psychological_func │\n",
       "│ tions_and_conscious_states \\\\\\\\[PDF]\\\\n3. **Attention - The Oxford Handbook of Attention**\\\\n   *Summary*: This │\n",
       "│ chapter from the Oxford Handbook of Attention provides an overview of attention as a fundamental aspect of      │\n",
       "│ cognition. It discusses the research community's engagement with attention and its various facets, including    │\n",
       "│ selective attention, sustained attention, and divided attention.\\\\n   *Link*:                                   │\n",
       "│ https://www.brainandcognition.org/wp-content/uploads/2015/07/Attention.pdf \\\\\\\\[PDF]\"}                          │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: Here are 3 articles about attention along with summaries and links:\\n1. **Attention: Theory, </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Principles, Models and Applications**\\n   *Summary*: This article discusses theories of attention from which models</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">and principles are derived, focusing on a descriptive model of human attention and performance. It explores how </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">principles of attention can be applied in design to remediate attention-related problems.\\n   *Link*: </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">https://www.researchgate.net/publication/349082014_Attention_Theory_Principles_Models_and_Applications \\\\[PDF]\\n2. </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**Attention: Multiple types, brain resonances, psychological functions and conscious states**\\n   *Summary*: This </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">article delves into neural models of attention, explaining how brain processes of consciousness, learning, </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">expectation, and attention interact. It highlights the role of brain resonances in different types of attention and</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">their impact on conscious states.\\n   *Link*: </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">https://www.researchgate.net/publication/350586329_Attention_Multiple_types_brain_resonances_psychological_function</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">s_and_conscious_states \\\\[PDF]\\n3. **Attention - The Oxford Handbook of Attention**\\n   *Summary*: This chapter </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">from the Oxford Handbook of Attention provides an overview of attention as a fundamental aspect of cognition. It </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">discusses the research community's engagement with attention and its various facets, including selective attention,</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">sustained attention, and divided attention.\\n   *Link*: </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">https://www.brainandcognition.org/wp-content/uploads/2015/07/Attention.pdf \\\\[PDF]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: Here are 3 articles about attention along with summaries and links:\\n1. **Attention: Theory, \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mPrinciples, Models and Applications**\\n   *Summary*: This article discusses theories of attention from which models\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mand principles are derived, focusing on a descriptive model of human attention and performance. It explores how \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mprinciples of attention can be applied in design to remediate attention-related problems.\\n   *Link*: \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mhttps://www.researchgate.net/publication/349082014_Attention_Theory_Principles_Models_and_Applications \\\\[PDF]\\n2. \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**Attention: Multiple types, brain resonances, psychological functions and conscious states**\\n   *Summary*: This \u001b[0m\n",
       "\u001b[1;38;2;212;183;2marticle delves into neural models of attention, explaining how brain processes of consciousness, learning, \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mexpectation, and attention interact. It highlights the role of brain resonances in different types of attention and\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mtheir impact on conscious states.\\n   *Link*: \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mhttps://www.researchgate.net/publication/350586329_Attention_Multiple_types_brain_resonances_psychological_function\u001b[0m\n",
       "\u001b[1;38;2;212;183;2ms_and_conscious_states \\\\[PDF]\\n3. **Attention - The Oxford Handbook of Attention**\\n   *Summary*: This chapter \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mfrom the Oxford Handbook of Attention provides an overview of attention as a fundamental aspect of cognition. It \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mdiscusses the research community's engagement with attention and its various facets, including selective attention,\u001b[0m\n",
       "\u001b[1;38;2;212;183;2msustained attention, and divided attention.\\n   *Link*: \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mhttps://www.brainandcognition.org/wp-content/uploads/2015/07/Attention.pdf \\\\[PDF]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 4: Duration 17.15 seconds| Input tokens: 14,129 | Output tokens: 418]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 4: Duration 17.15 seconds| Input tokens: 14,129 | Output tokens: 418]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(1):\n",
    "    message = input()\n",
    "    try:\n",
    "        result = agent.run(message)\n",
    "        results += [result]\n",
    "    except Exception as e:\n",
    "        results += [f\"Возникла ошибка: {e}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5348f49e-6a22-432b-bedb-dedfb1d4f0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 3 articles about attention along with summaries and links:\n",
      "1. Attention: Theory, Principles, Models and Applications\n",
      "   Summary: This article discusses theories of attention from which models and principles are derived, focusing on a descriptive model of human attention and performance. It explores how principles of attention can be applied in design to remediate attention-related problems.\n",
      "   Link: https://www.researchgate.net/publication/349082014_Attention_Theory_Principles_Models_and_Applications \\\\[PDF]\n",
      "2. Attention: Multiple types, brain resonances, psychological functions and conscious states\n",
      "   Summary: This article delves into neural models of attention, explaining how brain processes of consciousness, learning, expectation, and attention interact. It highlights the role of brain resonances in different types of attention and their impact on conscious states.\n",
      "   Link: https://www.researchgate.net/publication/350586329_Attention_Multiple_types_brain_resonances_psychological_functions_and_conscious_states \\\\[PDF]\n",
      "3. Attention - The Oxford Handbook of Attention\n",
      "   Summary: This chapter from the Oxford Handbook of Attention provides an overview of attention as a fundamental aspect of cognition. It discusses the research community's engagement with attention and its various facets, including selective attention, sustained attention, and divided attention.\n",
      "   Link: https://www.brainandcognition.org/wp-content/uploads/2015/07/Attention.pdf \\\\[PDF]\n"
     ]
    }
   ],
   "source": [
    "text = results[0].replace(\"\\\\n\", \"\\n\").replace('*', '')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4735b831-d4bf-4c3e-a0d5-3b6d5365c93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
