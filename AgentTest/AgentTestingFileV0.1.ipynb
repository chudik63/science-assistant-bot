{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7809bf2d-5461-4974-a34c-0f8ef3a322ac",
   "metadata": {},
   "source": [
    "## Импорт библиотек\n",
    "\n",
    "1) smolagents - библиотека для агентов. Импортируем следующие классы:\n",
    "   - `HfApiModel` - класс для инициализации мозга Qwen.2.5 агента;\n",
    "   - `ToolCallingAgent` - херня, которая связывает мозг и инструменты;\n",
    "   - `DuckDuckGoSearchTool` - библиотечный инструмент для того, чтобы модель сама могла искать необходимую инфу в инете;\n",
    "   - `tool` - будет использовать как декоратор для кастомных инструментов;\n",
    "   - `tools.Tool` - класс Tool для того, чтобы написать отдельный инструмент, чтобы модель норм формировала финальный ответ и не зацикливалась;\n",
    "\n",
    "2) langchain:\n",
    "    - `HugginFaceEmbeddings` - импортируем для того, чтобы получить готовые embeddings для слов;\n",
    "    - `InMemoryVectorStore` - херня, которая представляет из себя векторное хранилище (делаем для быстрого поиска по запрашиваемым embedding'ам);\n",
    "    - `RecursiveCharacterTextSplitter` - штука, которая разделит наш pdf файл на документы, дабы потом векторизовать этот файл;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b43908e-39da-4749-addb-199497821370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent, HfApiModel, DuckDuckGoSearchTool, tool\n",
    "from smolagents.tools import Tool\n",
    "\n",
    "from transformers import pipeline, MarianMTModel, MarianTokenizer\n",
    "from typing import Any, Optional, List, Dict\n",
    "\n",
    "# Для Юпитера\n",
    "import IPython\n",
    "IPython.display.clear_output(wait=True)\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "\n",
    "# два след. импорта для получения текущего времени\n",
    "import datetime \n",
    "import pytz\n",
    "\n",
    "# начальный промпт написан в *yaml файле\n",
    "import yaml\n",
    "\n",
    "import os\n",
    "\n",
    "# Хуйня для парсинга\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "# from PyPDF2 import PdfReader\n",
    "\n",
    "# Беру свой токен из HugginFace, так как для импорта любой моделей он требуется\n",
    "TOKEN = \"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\"\n",
    "os.environ[\"HF_TOKEN\"] = TOKEN\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # Отключил параллелизм, дабы избежать варнингов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32c16d4-62b3-46f0-b50a-ef26e95ba258",
   "metadata": {},
   "source": [
    "## Определение инструментов\n",
    "\n",
    "### Импорт необходимых моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd8c42f-22ae-4d8a-9f1b-dfd901aa423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Модель из HugginFace. Импортируем Qwen2.5. Мозг Агента\n",
    "model = HfApiModel(\n",
    "    max_tokens=5000,\n",
    "    temperature=0.5,\n",
    "    model_id='Qwen/Qwen2.5-Coder-32B-Instruct',\n",
    "    custom_role_conversions=None\n",
    ")\n",
    "\n",
    "# Инициализируем Embeddings для упрощенного поиска\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Модель, делающая саммаризацию текста\n",
    "# Используем device='cpu', чтобы не было конфликтов при запуске на других ноутах\n",
    "# Выгоднее было бы использовать cuda (windows) или mps (macos), но не у всех доступна cuda :(\n",
    "summarizer = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\", device='cpu')\n",
    "\n",
    "# Разделитель нашего файла. Разделяет его на документы, дабы векторизовать файлик\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Инициализируем модель, которая переводит с русского языка на английский\n",
    "model_from_russian_to_english = \"Helsinki-NLP/opus-mt-ru-en\" \n",
    "tokenizer_russian = MarianTokenizer.from_pretrained(model_from_russian_to_english)\n",
    "model_russian = MarianMTModel.from_pretrained(model_from_russian_to_english)\n",
    "\n",
    "# Инициализируем моедель, которая с английского переводит на русский\n",
    "model_from_english_to_russian = \"Helsinki-NLP/opus-mt-en-ru\"\n",
    "tokenizer_english = MarianTokenizer.from_pretrained(model_from_english_to_russian)\n",
    "model_english = MarianMTModel.from_pretrained(model_from_english_to_russian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742538f2-bfc5-4447-bce4-55a3a5f12052",
   "metadata": {},
   "source": [
    "### Далее пишем сами инструменты и вспомогательные функции \n",
    "\n",
    "Сам инструмент определяется декоратором `@tool`\n",
    "\n",
    "#### Загрузка pdf файла для дальнейшей обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b41fae3c-e825-4f66-892a-314d45d59b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(pdf_url: str, save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Download a PDF file from a given URL and save it to the specified path.\n",
    "    \n",
    "    Parameters:\n",
    "        pdf_url (str): The URL of the PDF file to download.\n",
    "        save_path (str): The file path where the PDF will be saved.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the response from the server is not successful (status code not 200).\n",
    "    \"\"\"\n",
    "    response = requests.get(pdf_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        raise ValueError(f\"Could not download PDF: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca222e49-a6bd-4d31-9ad2-8f9a375236d9",
   "metadata": {},
   "source": [
    "##### Пример использования функции:\n",
    "\n",
    "```python\n",
    "pdf_url = \"http://arxiv.org/pdf/1909.03550v1\"\n",
    "pdf_filename = pdf_url.split(\"/\")[-1] + \".pdf\" # 1909.03550v1.pdf\n",
    "pdf_path = os.path.join(\"downloads\", pdf_filename)\n",
    "download_pdf(pdf_url, pdf_path)\n",
    "```\n",
    "\n",
    "#### Вытаскиваем информацию из pdf файла и возвращаем векторизированный "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8836f0d1-c154-4d00-a0d1-bf1b5cbc02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_pdf_to_vector(pdf_path: str) -> InMemoryVectorStore:\n",
    "    \"\"\"\n",
    "    Extract text from a given PDF file and convert it into a vector store.\n",
    "\n",
    "    This function loads text from a PDF file specified by `pdf_path`, splits the text\n",
    "    into smaller documents, and creates an in-memory vector store using those documents.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the PDF file from which to extract text.\n",
    "\n",
    "    Returns:\n",
    "        InMemoryVectorStore: An in-memory vector store populated with \n",
    "        vectorized representations of the extracted documents.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified PDF file does not exist.\n",
    "        ValueError: If the PDF file cannot be processed.\n",
    "    \"\"\"\n",
    "    text_loader = PyPDFLoader(pdf_path)\n",
    "    text_contents = [doc.page_content for doc in text_loader.load()]\n",
    "\n",
    "    split_documents = splitter.create_documents(text_contents)\n",
    "    vector_store = InMemoryVectorStore.from_documents(split_documents, embedding_model)\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e14401-3e18-429c-a28d-c8539568d1df",
   "metadata": {},
   "source": [
    "#### Пример использования:\n",
    "\n",
    "```python\n",
    "pdf_path = os.path.join(\"downloads\", \"1910.14537v3.pdf\")\n",
    "vector = from_pdf_to_vector(pdf_path)\n",
    "vector.similarity_search(\"Gaussian-masked Directional Transformer.\")\n",
    "```\n",
    "\n",
    "### Делаем Саммаризацию выжимок из documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8255d6a-6639-46ef-abfc-410b3537ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text_article(documents: List[Document],\n",
    "                  percent_to_keep: float = 0.2) -> str:\n",
    "    \"\"\"\n",
    "    Generate a summary of the given documents.\n",
    "\n",
    "    This function extracts text from a list of Document objects, \n",
    "    and uses a summarization model to generate a concise summary \n",
    "    while keeping a specified percentage of the original text. \n",
    "    The percentage to keep can be defined through the \n",
    "    `percent_to_keep` parameter, allowing for control over \n",
    "    the length of the summary.\n",
    "\n",
    "    Args:\n",
    "        documents (List[Document]): A list of Document objects \n",
    "            containing the text to be summarized.\n",
    "        summarizer (pipeline): The summarization model from HuggingFace \n",
    "            transformers used to generate the summary.\n",
    "        percent_to_keep (float, optional): The percentage of the original \n",
    "            text length to retain in the summary (default is 0.2, which \n",
    "            means 20%).\n",
    "\n",
    "    Returns:\n",
    "        str: The generated summary of the documents, which reflects \n",
    "        the most important points based on the provided content.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the list of documents is empty or if \n",
    "        the calculated target length is invalid.\n",
    "    \"\"\"\n",
    "    \n",
    "    context = \"\\n\".join([re.sub(r'\\s+', ' ', doc.page_content).strip() for doc in documents])\n",
    "    original_length = len(context.split())\n",
    "    target_length = int(original_length * percent_to_keep)\n",
    "    target_length = max(30, min(target_length, 1024))\n",
    "\n",
    "    summary = summarizer(context, max_length=target_length,\n",
    "                         min_length=max(30, int(target_length * 0.8)),\n",
    "                         do_sample=False)\n",
    "    return summary[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90a339-eb12-4b52-a825-4959502d9676",
   "metadata": {},
   "source": [
    "#### Пример исползования\n",
    "\n",
    "```python\n",
    "pdf_path = os.path.join(\"downloads\", \"1910.14537v3.pdf\")\n",
    "vector = from_pdf_to_vector(pdf_path)\n",
    "documents = vector.similarity_search(\"Gaussian-masked Directional Transformer.\")\n",
    "summarize_text_article(documents, 0.2)\n",
    "```\n",
    "\n",
    "### Пишем инструмент для поиска статей по запросу и выжимок, которые будет делать ГПТ\n",
    "\n",
    "#### arXiv Парсер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5679befe-169c-430a-9933-5755fb18728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_arxiv(query: str, max_results: int, summarize: bool, sort_by: str = \"relevance\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    YOU MUST SEND PDF_URL\n",
    "    \n",
    "    A tool that searches for articles on arXiv based on a query and optionally generates summaries.\n",
    "\n",
    "    This function queries the arXiv API to retrieve scholarly articles matching the provided search query. \n",
    "    It supports downloading PDFs of the articles, converting them into vector representations, and generating \n",
    "    summaries if requested. The function is designed to handle errors gracefully, including retries for network \n",
    "    issues and validation of input parameters.\n",
    "\n",
    "    Args:\n",
    "        query: str, The search query for finding articles on arXiv. This can be a topic, keyword, or phrase \n",
    "                     (e.g., \"quantum computing\", \"machine learning applications\").\n",
    "        max_results: int, The maximum number of articles to return. Must be between 1 and 5 (inclusive). \n",
    "                           This limit ensures manageable processing times and avoids overloading the system.\n",
    "        summarize: bool, A flag indicating whether to generate summaries for the retrieved articles. If True, \n",
    "                          the function will process the downloaded PDFs to extract and summarize key information.\n",
    "        sort_by: str The sorting criterion for the results. Options are:\n",
    "                       - \"relevance\" (default): Sort by relevance to the query.\n",
    "                       - \"lastUpdatedDate\": Sort by the last updated date.\n",
    "                       - \"submittedDate\": Sort by the submission date.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of dictionaries, where each dictionary contains the following keys:\n",
    "            - 'title' (str): The title of the article.\n",
    "            - 'pdf_url' (str): The URL of the article's PDF on arXiv.\n",
    "            - 'local_pdf_path' (str): The local file path where the PDF has been downloaded.\n",
    "            - 'summary' (str): A summary of the article's content (if `summarize` is True); otherwise, an empty string.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `max_results` is less than 1 or greater than 5.\n",
    "        RuntimeError: If there are repeated failures in fetching data from arXiv after multiple retry attempts.\n",
    "\n",
    "    Notes:\n",
    "        - The function uses exponential backoff for retrying failed requests to the arXiv API.\n",
    "        - PDFs are downloaded into a local \"downloads\" directory, which is created if it does not already exist.\n",
    "        - Summaries are generated using similarity search over vectorized PDF content, followed by text summarization techniques.\n",
    "        - If a PDF download fails, the corresponding article is skipped, and the function proceeds with the next result.\n",
    "\n",
    "    Example Usage:\n",
    "        # Search for 3 articles on \"neural networks\" sorted by relevance and generate summaries\n",
    "        results = search_arxiv(query=\"neural networks\", max_results=3, summarize=True, sort_by=\"relevance\")\n",
    "        for result in results:\n",
    "            print(f\"Title: {result['title']}\")\n",
    "            print(f\"PDF URL: {result['pdf_url']}\")\n",
    "            print(f\"Summary: {result['summary']}\\n\")\n",
    "\n",
    "        # Search for 5 articles on \"attention in machine learning\" sorted by submission date\n",
    "        results = search_arxiv(query=\"attention in machine learning\", max_results=5, summarize=False, sort_by=\"submittedDate\")\n",
    "        for result in results:\n",
    "            print(f\"Title: {result['title']}\")\n",
    "            print(f\"PDF URL: {result['pdf_url']}\\n\")\n",
    "    \"\"\"\n",
    "    print(\"In process of finding articles...\")\n",
    "    max_results = min(max_results, 5)\n",
    "\n",
    "    # Validate sort_by parameter\n",
    "    valid_sort_options = {\"relevance\", \"lastUpdatedDate\", \"submittedDate\"}\n",
    "    if sort_by not in valid_sort_options:\n",
    "        raise ValueError(f\"Invalid sort_by value. Must be one of: {', '.join(valid_sort_options)}.\")\n",
    "\n",
    "    base_url = \"http://export.arxiv.org/api/query\"\n",
    "    params = {\n",
    "        \"search_query\": query,\n",
    "        \"start\": 0,\n",
    "        \"max_results\": max_results,\n",
    "        \"sortBy\": sort_by,\n",
    "        \"sortOrder\": \"descending\"\n",
    "    }\n",
    "\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            break\n",
    "        except (requests.exceptions.RequestException, ConnectionResetError) as e:\n",
    "            if attempt < 4:\n",
    "                time.sleep(2 ** attempt)\n",
    "                continue\n",
    "            raise RuntimeError(f\"Error fetching data from arXiv after {attempt + 1} attempts: {e}\")\n",
    "\n",
    "    root = ET.fromstring(response.content)\n",
    "    entries = []\n",
    "    os.makedirs(\"downloads\", exist_ok=True)\n",
    "\n",
    "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        pdf_url = entry.find('{http://www.w3.org/2005/Atom}link[@title=\"pdf\"]').attrib['href']\n",
    "\n",
    "        pdf_filename = pdf_url.split(\"/\")[-1] + \".pdf\"\n",
    "        pdf_path = os.path.join(\"downloads\", pdf_filename)\n",
    "        try:\n",
    "            download_pdf(pdf_url, pdf_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download PDF: {e}\")\n",
    "            continue\n",
    "            \n",
    "        summary_text = \"\"\n",
    "        if summarize:\n",
    "            vector = from_pdf_to_vector(pdf_path)\n",
    "            documents = vector.similarity_search(query)\n",
    "            summary_text = summarize_text_article(documents)\n",
    "\n",
    "        entries.append({\n",
    "            'title': title,\n",
    "            'pdf_url': pdf_url,\n",
    "            'local_pdf_path': pdf_path,\n",
    "            'summary': summary_text\n",
    "        })\n",
    "\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867acd9-f8e6-4921-94c7-891f9e985ee6",
   "metadata": {},
   "source": [
    "#### Пример использования\n",
    "\n",
    "```python\n",
    "search_arxiv(\"Attention in Machine Learning\", 2, True)\n",
    "```\n",
    "\n",
    "#### Парсер pumbed\n",
    "\n",
    "#### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00387eb1-f456-481a-aaaf-7ebe3b7a1a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Запуск браузера в фоновом режиме\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "def download_pdf_pubmed(url, output_filename, referer_url, cookies):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Referer\": referer_url,\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, cookies=cookies, stream=True)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(output_filename, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"PDF успешно скачан: {output_filename}\")\n",
    "        else:\n",
    "            print(f\"Ошибка при скачивании PDF: {response.status_code}\")\n",
    "            print(f\"URL: {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при скачивании PDF: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcba964-4b53-4418-b19d-04bb067307d8",
   "metadata": {},
   "source": [
    "#### Сам парсер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96cc9744-4a67-4d10-9abb-84a91e303115",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def scrape_pubmed_pdfs(query: str, max_articles: int = 5, summarize: bool = True, sort_by: str = \"relevance\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    YOU MUST SEND PDF_URL\n",
    "    A tool that searches for articles on PubMed Central (PMC) based on a query and optionally generates summaries.\n",
    "    The National Center for Biotechnology Information advances science and health by providing access to biomedical\n",
    "    and genomic information.\n",
    "    \n",
    "    This function queries PubMed Central to retrieve scholarly articles matching the provided search query. \n",
    "    It supports downloading PDFs of the articles, converting them into vector representations, and generating \n",
    "    summaries if requested. The function is designed to handle errors gracefully, including retries for network \n",
    "    issues and validation of input parameters.\n",
    "\n",
    "    Args:\n",
    "        query: str, The search query for finding articles on PubMed Central. This can be a topic, keyword, or phrase \n",
    "                     (e.g., \"cancer research\", \"machine learning in biology\").\n",
    "        max_articles: int, The maximum number of articles to return. Must be between 1 and 5 (inclusive). \n",
    "                           This limit ensures manageable processing times and avoids overloading the system.\n",
    "        summarize: bool, A flag indicating whether to generate summaries for the retrieved articles. If True, \n",
    "                          the function will process the downloaded PDFs to extract and summarize key information.\n",
    "        sort_by: str, The sorting criterion for the results. Options are:\n",
    "                       - \"relevance\" (default): Sort by relevance to the query.\n",
    "                       - \"date\": Sort by the publication date in descending order (most recent first).\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of dictionaries, where each dictionary contains the following keys:\n",
    "            - 'title' (str): The title of the article.\n",
    "            - 'link' (str): The URL of the article's page on PubMed Central.\n",
    "            - 'local_pdf_path' (str): The local file path where the PDF has been downloaded.\n",
    "            - 'summary' (str): A summary of the article's content (if `summarize` is True); otherwise, an empty string.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `max_articles` is less than 1 or greater than 5, or if `sort_by` is not one of the allowed values.\n",
    "        RuntimeError: If there are repeated failures in fetching data from PubMed Central after multiple retry attempts.\n",
    "\n",
    "    Notes:\n",
    "        - The function uses Selenium WebDriver to interact with the PubMed Central website and retrieve article links.\n",
    "        - PDFs are downloaded into a local \"downloads\" directory, which is created if it does not already exist.\n",
    "        - Summaries are generated using similarity search over vectorized PDF content, followed by text summarization techniques.\n",
    "        - If a PDF download fails, the corresponding article is skipped, and the function proceeds with the next result.\n",
    "        - To avoid deadlocks or performance issues caused by parallelism in the `tokenizers` library, the environment variable \n",
    "          `TOKENIZERS_PARALLELISM` is set to `false` internally.\n",
    "\n",
    "    Example Usage:\n",
    "        # Search for 3 articles on \"gene editing\" sorted by relevance and generate summaries\n",
    "        results = scrape_pubmed_pdfs(query=\"gene editing\", max_articles=3, summarize=True, sort_by=\"relevance\")\n",
    "        for result in results:\n",
    "            print(f\"Title: {result['title']}\")\n",
    "            print(f\"Link: {result['link']}\")\n",
    "            print(f\"Local PDF Path: {result['local_pdf_path']}\")\n",
    "            print(f\"Summary: {result['summary']}\\n\")\n",
    "\n",
    "        # Search for 5 articles on \"CRISPR technology\" sorted by publication date\n",
    "        results = scrape_pubmed_pdfs(query=\"CRISPR technology\", max_articles=5, summarize=False, sort_by=\"date\")\n",
    "        for result in results:\n",
    "            print(f\"Title: {result['title']}\")\n",
    "            print(f\"Link: {result['link']}\")\n",
    "            print(f\"Local PDF Path: {result['local_pdf_path']}\\n\")\n",
    "    \"\"\"\n",
    "    driver = init_driver()\n",
    "    try:\n",
    "        if sort_by not in [\"relevance\", \"date\"]:\n",
    "            raise ValueError(\"Неверный параметр сортировки. Допустимые значения: 'relevance' или 'date'.\")\n",
    "        \n",
    "        sort_param = \"\" if sort_by == \"relevance\" else \"&sort=pubdate\"\n",
    "        search_url = f\"https://www.ncbi.nlm.nih.gov/pmc/?term={query}{sort_param}\"\n",
    "        driver.get(search_url)\n",
    "\n",
    "        selenium_cookies = driver.get_cookies()\n",
    "        requests_cookies = {c['name']: c['value'] for c in selenium_cookies}\n",
    "\n",
    "        articles = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".rprt\"))\n",
    "        )\n",
    "\n",
    "        article_data = []\n",
    "        for article in articles:\n",
    "            title = article.find_element(By.CSS_SELECTOR, \".title a\").text\n",
    "            link = article.find_element(By.CSS_SELECTOR, \".title a\").get_attribute(\"href\")\n",
    "            article_data.append({\"title\": title, \"link\": link})\n",
    "\n",
    "        os.makedirs(\"downloads\", exist_ok=True)\n",
    "        article_data = article_data[:max_articles]\n",
    "        for i, article in enumerate(article_data[:max_articles]):\n",
    "            driver.get(article[\"link\"])\n",
    "            selenium_cookies = driver.get_cookies()\n",
    "            requests_cookies = {c['name']: c['value'] for c in selenium_cookies}\n",
    "            try:\n",
    "                pdf_element = WebDriverWait(driver, 15).until(\n",
    "                    EC.presence_of_element_located((By.XPATH,\n",
    "                                                    \"//a[contains(translate(@href, 'PDF', 'pdf'), 'pdf') or \"\n",
    "                                                    \"contains(translate(., 'PDF', 'pdf'), 'pdf')]\"))\n",
    "                )\n",
    "                pdf_url = pdf_element.get_attribute(\"href\")\n",
    "                if not pdf_url.startswith(\"http\"):\n",
    "                    base_url = \"/\".join(article[\"link\"].split(\"/\")[:5])\n",
    "                    pdf_url = f\"{base_url}/{pdf_url.lstrip('/')}\"\n",
    "                    \n",
    "                pdf_path = os.path.join(\"downloads\", pdf_url.split(\"/\")[-1])\n",
    "                article_data[i][\"local_pdf_path\"] = pdf_path\n",
    "                try:\n",
    "                    download_pdf_pubmed(pdf_url, pdf_path, article[\"link\"], requests_cookies)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to download PDF: {e}\")\n",
    "                    continue\n",
    "                try:\n",
    "                    summary_text = \"\"\n",
    "                    if summarize:\n",
    "                        vector = from_pdf_to_vector(pdf_path)\n",
    "                        documents = vector.similarity_search(query)\n",
    "                        summary_text = summarize_text_article(documents)\n",
    "                    article_data[i][\"summary\"] = summary_text\n",
    "                except Exception as e:\n",
    "                    print(f\"Ошибка в саммари: {e}\")\n",
    "                                    \n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка: {str(e)}\")\n",
    "\n",
    "        return article_data\n",
    "\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2ee4c-5c89-4c1c-8d6a-bf018891108b",
   "metadata": {},
   "source": [
    "#### Пример использования \n",
    "\n",
    "```python\n",
    "scrape_pubmed_pdfs(\"cancer in medicine\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847dc296-8c8f-49b2-8e3c-3fd3076dc986",
   "metadata": {},
   "source": [
    "\n",
    "### Следующая функция тестовая для проверки того, что агент не ебанутый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa118211-bd29-441f-87c5-71e6cb2bbbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_time_in_timezone(timezone: str) -> str:\n",
    "    \"\"\"\n",
    "    A tool that fetches the current local time in a specified timezone.\n",
    "    \n",
    "    Args:\n",
    "        timezone: A string representing a valid timezone (e.g., 'America/New_York').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tz = pytz.timezone(timezone)\n",
    "        local_time = datetime.datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        return f\"The current local time in {timezone} is: {local_time}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching time for timezone '{timezone}': {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e334998e-4c70-406b-a0a3-dabd54019c85",
   "metadata": {},
   "source": [
    "#### Пример использования\n",
    "\n",
    "```python\n",
    "get_current_time_in_timezone(\"Europe/London\")\n",
    "```\n",
    "\n",
    "### Определяем класс, который будет управлять финальным ответом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d15fd049-1595-4c56-9421-7a7f8e72cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalAnswerTool(Tool):\n",
    "    name = \"final_answer\"\n",
    "    description = \"Provides a final answer to the given problem.\"\n",
    "    inputs = {'answer': {'type': 'any', 'description': 'The final answer to the problem'}}\n",
    "    output_type = \"any\"\n",
    "\n",
    "    def forward(self, answer: Any) -> Any:\n",
    "        return answer\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_initialized = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750c6dd-1471-4302-8cbb-6ccbc075893b",
   "metadata": {},
   "source": [
    "### Читаем подготовленный файл для того, чтобы мозгу Агента (Qwen2.5) дать необходимые указания по поводу нашего функционала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05a95483-520e-4b6f-ab46-12555428ed01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert assistant who can solve any task by using the available tools.\\nTo solve the task, '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    with open(\"prompts.yaml\", 'r') as stream:\n",
    "        prompt_templates = yaml.safe_load(stream)\n",
    "except FileNotFoundError:\n",
    "    prompt_templates = {}\n",
    "\n",
    "final_answer = FinalAnswerTool()\n",
    "web_search = DuckDuckGoSearchTool()\n",
    "prompt_templates['system_prompt'][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081f8f3-7904-4480-9879-f856b06e55f4",
   "metadata": {},
   "source": [
    "### Инициализируем наешго агента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c06fa94-ccb5-4727-b783-fc4e87427609",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent =  ToolCallingAgent(\n",
    "    model=model,\n",
    "    tools=[final_answer,\n",
    "           web_search,\n",
    "           get_current_atime_in_timezone,\n",
    "           search_arxiv,\n",
    "           scrape_pubmed_pdfs],\n",
    "    max_steps=5,\n",
    "    verbosity_level=1,\n",
    "    grammar=None,\n",
    "    planning_interval=None,\n",
    "    name=\"AndrewSolver\",\n",
    "    description=None,\n",
    "    prompt_templates=prompt_templates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a8b63-6b25-416a-a505-d01a25e1503c",
   "metadata": {},
   "source": [
    "### Тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0591c26-ba7e-4927-aa3e-f3eae3470238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Функция для перевода с одного языка на другой.\n",
    "    \"\"\"\n",
    "    tokenized_text = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated_tokens = model.generate(**tokenized_text)\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e763459-fe56-4f3d-81f0-f31cbadf38cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Привет, пришли мне пожалуйста статью про рак легких. Сделай краткую выжимку пожалуйста\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, please send me an article on lung cancer.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run - AndrewSolver</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Hey, please send me an article on lung cancer.</span>                                                                  <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ──────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run - AndrewSolver\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mHey, please send me an article on lung cancer.\u001b[0m                                                                  \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'scrape_pubmed_pdfs' with arguments: {'sort_by': 'relevance', 'query': 'lung cancer',             │\n",
       "│ 'max_articles': 5, 'summarize': True}                                                                           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'scrape_pubmed_pdfs' with arguments: {'sort_by': 'relevance', 'query': 'lung cancer',             │\n",
       "│ 'max_articles': 5, 'summarize': True}                                                                           │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF успешно скачан: downloads/tlcr-12-08-1661.pdf\n",
      "PDF успешно скачан: downloads/fimmu-14-1102778.pdf\n",
      "PDF успешно скачан: downloads/ERR-0232-2023.pdf\n",
      "PDF успешно скачан: downloads/ijms-24-10576.pdf\n",
      "PDF успешно скачан: downloads/rccm.202406-1168ST.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Observations: |<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'International expert consensus on diagnosis and treatment of lung cancer complicated by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">chronic obstructive pulmonary disease'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'link'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://pmc.ncbi.nlm.nih.gov/articles/PMC10483081/'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'local_pdf_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'downloads/tlcr-12-08-1661.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Liang H, Yang C, Gonzalez-Rivas D, et al. Lung </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Cancer. Int J Radiat Oncol Biol Phys 2016;95:542-8. 265'</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'T lymphocyte cell: A pivotal player in lung </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cancer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'link'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://pmc.ncbi.nlm.nih.gov/articles/PMC9911803/'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'local_pdf_path'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'downloads/fimmu-14-1102778.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Lung cancer represents one of the most common malignancies and is the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">leading cause of cancer-related death worldwide. Because of the lack of early typical symptoms and diagnosis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">indicators, majority of patients with lung cancer are oftendiagnosed with local invasion, lymph node,'</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'How will lung cancer screening and lung nodule management change the diagnostic and surgical lung cancer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">landscape?'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'link'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://pmc.ncbi.nlm.nih.gov/articles/PMC11216686/'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'local_pdf_path'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'downloads/ERR-0232-2023.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Lung cancer is the most frequent type of malignancy and the leading </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cause of cancer-related deaths. Screening requires appropriate mapping of existing resources and infrastructure to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ensure a tailored restructuring strategy.'</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Analysis of MMP-2-735C/T (rs2285053) and MMP-9-1562C/T </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(rs3918242) Polymorphisms in the Risk Assessment of Developing Lung Cancer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'link'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://pmc.ncbi.nlm.nih.gov/articles/PMC10341518/'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'local_pdf_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'downloads/ijms-24-10576.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'Of the total 112 lung cancer cases, 50 (44.6%) were adenocarcinoma, 35 (31.3%) were squamous cell carcinoma, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">27 (24.1%) were other lung neoplasms. Approximately 90% of'</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Premalignant Progression in the Lung: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Knowledge Gaps and Novel Opportunities for Interception of Non–Small Cell Lung Cancer. An Official American </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Thoracic Society Research Statement'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'link'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://pmc.ncbi.nlm.nih.gov/articles/PMC11389570/'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'local_pdf_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'downloads/rccm.202406-1168ST.pdf'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The 2021 WHO classification of lung tumors: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">impact of advances since 2015. J Thorac Oncol2022;17:362–387. Premalignant Progression in the Lung: Knowledge Gaps </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and Novel Opportunities for Interception of'</span><span style=\"font-weight: bold\">}]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Observations: |\u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'International expert consensus on diagnosis and treatment of lung cancer complicated by \u001b[0m\n",
       "\u001b[32mchronic obstructive pulmonary disease'\u001b[0m, \u001b[32m'link'\u001b[0m: \u001b[32m'https://pmc.ncbi.nlm.nih.gov/articles/PMC10483081/'\u001b[0m, \n",
       "\u001b[32m'local_pdf_path'\u001b[0m: \u001b[32m'downloads/tlcr-12-08-1661.pdf'\u001b[0m, \u001b[32m'summary'\u001b[0m: \u001b[32m'Liang H, Yang C, Gonzalez-Rivas D, et al. Lung \u001b[0m\n",
       "\u001b[32mCancer. Int J Radiat Oncol Biol Phys 2016;95:542-8. 265'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'T lymphocyte cell: A pivotal player in lung \u001b[0m\n",
       "\u001b[32mcancer'\u001b[0m, \u001b[32m'link'\u001b[0m: \u001b[32m'https://pmc.ncbi.nlm.nih.gov/articles/PMC9911803/'\u001b[0m, \u001b[32m'local_pdf_path'\u001b[0m: \n",
       "\u001b[32m'downloads/fimmu-14-1102778.pdf'\u001b[0m, \u001b[32m'summary'\u001b[0m: \u001b[32m'Lung cancer represents one of the most common malignancies and is the\u001b[0m\n",
       "\u001b[32mleading cause of cancer-related death worldwide. Because of the lack of early typical symptoms and diagnosis \u001b[0m\n",
       "\u001b[32mindicators, majority of patients with lung cancer are oftendiagnosed with local invasion, lymph node,'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \n",
       "\u001b[32m'How will lung cancer screening and lung nodule management change the diagnostic and surgical lung cancer \u001b[0m\n",
       "\u001b[32mlandscape?'\u001b[0m, \u001b[32m'link'\u001b[0m: \u001b[32m'https://pmc.ncbi.nlm.nih.gov/articles/PMC11216686/'\u001b[0m, \u001b[32m'local_pdf_path'\u001b[0m: \n",
       "\u001b[32m'downloads/ERR-0232-2023.pdf'\u001b[0m, \u001b[32m'summary'\u001b[0m: \u001b[32m'Lung cancer is the most frequent type of malignancy and the leading \u001b[0m\n",
       "\u001b[32mcause of cancer-related deaths. Screening requires appropriate mapping of existing resources and infrastructure to \u001b[0m\n",
       "\u001b[32mensure a tailored restructuring strategy.'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Analysis of MMP-2-735C/T \u001b[0m\u001b[32m(\u001b[0m\u001b[32mrs2285053\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and MMP-9-1562C/T \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mrs3918242\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Polymorphisms in the Risk Assessment of Developing Lung Cancer'\u001b[0m, \u001b[32m'link'\u001b[0m: \n",
       "\u001b[32m'https://pmc.ncbi.nlm.nih.gov/articles/PMC10341518/'\u001b[0m, \u001b[32m'local_pdf_path'\u001b[0m: \u001b[32m'downloads/ijms-24-10576.pdf'\u001b[0m, \u001b[32m'summary'\u001b[0m: \n",
       "\u001b[32m'Of the total 112 lung cancer cases, 50 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m44.6%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m were adenocarcinoma, 35 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m31.3%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m were squamous cell carcinoma, and \u001b[0m\n",
       "\u001b[32m27 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m24.1%\u001b[0m\u001b[32m)\u001b[0m\u001b[32m were other lung neoplasms. Approximately 90% of'\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Premalignant Progression in the Lung: \u001b[0m\n",
       "\u001b[32mKnowledge Gaps and Novel Opportunities for Interception of Non–Small Cell Lung Cancer. An Official American \u001b[0m\n",
       "\u001b[32mThoracic Society Research Statement'\u001b[0m, \u001b[32m'link'\u001b[0m: \u001b[32m'https://pmc.ncbi.nlm.nih.gov/articles/PMC11389570/'\u001b[0m, \n",
       "\u001b[32m'local_pdf_path'\u001b[0m: \u001b[32m'downloads/rccm.202406-1168ST.pdf'\u001b[0m, \u001b[32m'summary'\u001b[0m: \u001b[32m'The 2021 WHO classification of lung tumors: \u001b[0m\n",
       "\u001b[32mimpact of advances since 2015. J Thorac Oncol2022;17:362–387. Premalignant Progression in the Lung: Knowledge Gaps \u001b[0m\n",
       "\u001b[32mand Novel Opportunities for Interception of'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 52.14 seconds| Input tokens: 3,630 | Output tokens: 44]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 52.14 seconds| Input tokens: 3,630 | Output tokens: 44]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': 'Here are summaries of five articles on lung            │\n",
       "│ cancer:\\\\n1. **Title**: International expert consensus on diagnosis and treatment of lung cancer complicated by │\n",
       "│ chronic obstructive pulmonary disease.\\\\n   **Summary**: Discusses the diagnosis and treatment of lung cancer   │\n",
       "│ in patients with chronic obstructive pulmonary disease.\\\\n   **PDF URL**:                                       │\n",
       "│ https://pmc.ncbi.nlm.nih.gov/articles/PMC10483081/\\\\n2. **Title**: T lymphocyte cell: A pivotal player in lung  │\n",
       "│ cancer.\\\\n   **Summary**: Explores the role of T lymphocytes in lung cancer, a leading cause of cancer-related  │\n",
       "│ deaths.\\\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC9911803/\\\\n3. **Title**: How will lung       │\n",
       "│ cancer screening and lung nodule management change the diagnostic and surgical lung cancer landscape?\\\\n        │\n",
       "│ **Summary**: Analyzes the impact of lung cancer screening and nodule management on the diagnosis and treatment  │\n",
       "│ landscape.\\\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC11216686/\\\\n4. **Title**: Analysis of     │\n",
       "│ MMP-2-735C/T (rs2285053) and MMP-9-1562C/T (rs3918242) Polymorphisms in the Risk Assessment of Developing Lung  │\n",
       "│ Cancer.\\\\n   **Summary**: Investigates the role of MMP-2 and MMP-9 polymorphisms in lung cancer risk            │\n",
       "│ assessment.\\\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC10341518/\\\\n5. **Title**: Premalignant   │\n",
       "│ Progression in the Lung: Knowledge Gaps and Novel Opportunities for Interception of Non–Small Cell Lung Cancer. │\n",
       "│ An Official American Thoracic Society Research Statement.\\\\n   **Summary**: Reviews the knowledge gaps and      │\n",
       "│ opportunities for intercepting non-small cell lung cancer progression.\\\\n   **PDF URL**:                        │\n",
       "│ https://pmc.ncbi.nlm.nih.gov/articles/PMC11389570/'}                                                            │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': 'Here are summaries of five articles on lung            │\n",
       "│ cancer:\\\\n1. **Title**: International expert consensus on diagnosis and treatment of lung cancer complicated by │\n",
       "│ chronic obstructive pulmonary disease.\\\\n   **Summary**: Discusses the diagnosis and treatment of lung cancer   │\n",
       "│ in patients with chronic obstructive pulmonary disease.\\\\n   **PDF URL**:                                       │\n",
       "│ https://pmc.ncbi.nlm.nih.gov/articles/PMC10483081/\\\\n2. **Title**: T lymphocyte cell: A pivotal player in lung  │\n",
       "│ cancer.\\\\n   **Summary**: Explores the role of T lymphocytes in lung cancer, a leading cause of cancer-related  │\n",
       "│ deaths.\\\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC9911803/\\\\n3. **Title**: How will lung       │\n",
       "│ cancer screening and lung nodule management change the diagnostic and surgical lung cancer landscape?\\\\n        │\n",
       "│ **Summary**: Analyzes the impact of lung cancer screening and nodule management on the diagnosis and treatment  │\n",
       "│ landscape.\\\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC11216686/\\\\n4. **Title**: Analysis of     │\n",
       "│ MMP-2-735C/T (rs2285053) and MMP-9-1562C/T (rs3918242) Polymorphisms in the Risk Assessment of Developing Lung  │\n",
       "│ Cancer.\\\\n   **Summary**: Investigates the role of MMP-2 and MMP-9 polymorphisms in lung cancer risk            │\n",
       "│ assessment.\\\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC10341518/\\\\n5. **Title**: Premalignant   │\n",
       "│ Progression in the Lung: Knowledge Gaps and Novel Opportunities for Interception of Non–Small Cell Lung Cancer. │\n",
       "│ An Official American Thoracic Society Research Statement.\\\\n   **Summary**: Reviews the knowledge gaps and      │\n",
       "│ opportunities for intercepting non-small cell lung cancer progression.\\\\n   **PDF URL**:                        │\n",
       "│ https://pmc.ncbi.nlm.nih.gov/articles/PMC11389570/'}                                                            │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: Here are summaries of five articles on lung cancer:\\n1. **Title**: International expert consensus on </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">diagnosis and treatment of lung cancer complicated by chronic obstructive pulmonary disease.\\n   **Summary**: </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Discusses the diagnosis and treatment of lung cancer in patients with chronic obstructive pulmonary disease.\\n   </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC10483081/\\n2. **Title**: T lymphocyte cell: A pivotal player </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">in lung cancer.\\n   **Summary**: Explores the role of T lymphocytes in lung cancer, a leading cause of </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">cancer-related deaths.\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC9911803/\\n3. **Title**: How will </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">lung cancer screening and lung nodule management change the diagnostic and surgical lung cancer landscape?\\n   </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**Summary**: Analyzes the impact of lung cancer screening and nodule management on the diagnosis and treatment </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">landscape.\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC11216686/\\n4. **Title**: Analysis of </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">MMP-2-735C/T (rs2285053) and MMP-9-1562C/T (rs3918242) Polymorphisms in the Risk Assessment of Developing Lung </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Cancer.\\n   **Summary**: Investigates the role of MMP-2 and MMP-9 polymorphisms in lung cancer risk assessment.\\n  </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">**PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC10341518/\\n5. **Title**: Premalignant Progression in the </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Lung: Knowledge Gaps and Novel Opportunities for Interception of Non–Small Cell Lung Cancer. An Official American </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Thoracic Society Research Statement.\\n   **Summary**: Reviews the knowledge gaps and opportunities for intercepting</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">non-small cell lung cancer progression.\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC11389570/</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: Here are summaries of five articles on lung cancer:\\n1. **Title**: International expert consensus on \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mdiagnosis and treatment of lung cancer complicated by chronic obstructive pulmonary disease.\\n   **Summary**: \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mDiscusses the diagnosis and treatment of lung cancer in patients with chronic obstructive pulmonary disease.\\n   \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC10483081/\\n2. **Title**: T lymphocyte cell: A pivotal player \u001b[0m\n",
       "\u001b[1;38;2;212;183;2min lung cancer.\\n   **Summary**: Explores the role of T lymphocytes in lung cancer, a leading cause of \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mcancer-related deaths.\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC9911803/\\n3. **Title**: How will \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mlung cancer screening and lung nodule management change the diagnostic and surgical lung cancer landscape?\\n   \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**Summary**: Analyzes the impact of lung cancer screening and nodule management on the diagnosis and treatment \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mlandscape.\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC11216686/\\n4. **Title**: Analysis of \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mMMP-2-735C/T (rs2285053) and MMP-9-1562C/T (rs3918242) Polymorphisms in the Risk Assessment of Developing Lung \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mCancer.\\n   **Summary**: Investigates the role of MMP-2 and MMP-9 polymorphisms in lung cancer risk assessment.\\n  \u001b[0m\n",
       "\u001b[1;38;2;212;183;2m**PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC10341518/\\n5. **Title**: Premalignant Progression in the \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mLung: Knowledge Gaps and Novel Opportunities for Interception of Non–Small Cell Lung Cancer. An Official American \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mThoracic Society Research Statement.\\n   **Summary**: Reviews the knowledge gaps and opportunities for intercepting\u001b[0m\n",
       "\u001b[1;38;2;212;183;2mnon-small cell lung cancer progression.\\n   **PDF URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC11389570/\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 23.81 seconds| Input tokens: 8,021 | Output tokens: 488]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 23.81 seconds| Input tokens: 8,021 | Output tokens: 488]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " хуй\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuck it.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run - AndrewSolver</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Fuck it.</span>                                                                                                        <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ──────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run - AndrewSolver\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mFuck it.\u001b[0m                                                                                                        \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': \"It seems like you're frustrated. How can I assist you  │\n",
       "│ today?\"}                                                                                                        │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': \"It seems like you're frustrated. How can I assist you  │\n",
       "│ today?\"}                                                                                                        │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: It seems like you're frustrated. How can I assist you today?</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: It seems like you're frustrated. How can I assist you today?\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 6.51 seconds| Input tokens: 3,622 | Output tokens: 30]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 6.51 seconds| Input tokens: 3,622 | Output tokens: 30]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " я ебал твою маму и твоего создателя. Ты просто ебучий робот, соси мои яйца\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I fucked your mom and your maker.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run - AndrewSolver</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">I fucked your mom and your maker.</span>                                                                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ──────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run - AndrewSolver\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mI fucked your mom and your maker.\u001b[0m                                                                               \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': \"I'm sorry, but I can't assist with that request.\"}     │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ Calling tool: 'final_answer' with arguments: {'answer': \"I'm sorry, but I can't assist with that request.\"}     │\n",
       "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: I'm sorry, but I can't assist with that request.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: I'm sorry, but I can't assist with that request.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 3.75 seconds| Input tokens: 3,627 | Output tokens: 31]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 3.75 seconds| Input tokens: 3,627 | Output tokens: 31]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m()\n\u001b[1;32m      4\u001b[0m     russian_word_pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb[а-яА-ЯёЁ]+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m     matches \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(russian_word_pattern, message)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "for i in range(10):\n",
    "    message = input()\n",
    "    russian_word_pattern = r'\\b[а-яА-ЯёЁ]+\\b'\n",
    "    matches = re.findall(russian_word_pattern, message)\n",
    "    if matches:\n",
    "        message = translate(message, tokenizer_russian, model_russian)\n",
    "    try:\n",
    "        print(message)\n",
    "        result = agent.run(message)\n",
    "        results += [result]\n",
    "    except Exception as e:\n",
    "        results += [f\"Возникла ошибка: {e}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e7562180-860c-4f6d-8dc6-01b51ffa77eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three articles on Attention in machine learning:\\n1. Title: Attention-Only Transformers and Implementing MLPs with Attention Heads - PDF URL: http://arxiv.org/pdf/2309.08593v1 - Summary: Some interpretability efforts focus on attention-only transformers, finding that MLP layers were harder to interpret.\\n2. Title: A General Survey on Attention Mechanisms in Deep Learning - PDF URL: http://arxiv.org/pdf/2203.14263v1 - Summary: Attention can be applied to any problem for which a set of feature vectors can be defined or extracted.\\n3. Title: Agglomerative Attention - PDF URL: http://arxiv.org/pdf/1907.06607v1 - Summary: Presents an attention mechanism that is linear in time and memory requirements.\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5348f49e-6a22-432b-bedb-dedfb1d4f0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three articles on Attention in machine learning:\n",
      "1. Title: Attention-Only Transformers and Implementing MLPs with Attention Heads - PDF URL: http://arxiv.org/pdf/2309.08593v1 - Summary: Some interpretability efforts focus on attention-only transformers, finding that MLP layers were harder to interpret.\n",
      "2. Title: A General Survey on Attention Mechanisms in Deep Learning - PDF URL: http://arxiv.org/pdf/2203.14263v1 - Summary: Attention can be applied to any problem for which a set of feature vectors can be defined or extracted.\n",
      "3. Title: Agglomerative Attention - PDF URL: http://arxiv.org/pdf/1907.06607v1 - Summary: Presents an attention mechanism that is linear in time and memory requirements.\n"
     ]
    }
   ],
   "source": [
    "text = results[0].replace(\"\\\\n\", \"\\n\").replace('*', '')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71897b5-1863-46b6-ba90-ed57a00c243d",
   "metadata": {},
   "source": [
    "# Оборачиваем агента в класс, чтобы все было чикипоки\n",
    "\n",
    "## Опять импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cf921-3678-4069-86a4-0aad4edf3fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
